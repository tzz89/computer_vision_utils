{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MeanAveragePrecision(mAP).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4owl8CV2C19"
      },
      "source": [
        "# In this notebook, we will be understanding the different metrics for computer vision tasks and subtasks.\n",
        "1. obejct detection bbox\n",
        "2. semantic segmentation\n",
        "3. instance segmentation\n",
        "4. pose/keypoint detection\n",
        "5. panoptic segmentation\n",
        "\n",
        "\n",
        "# Metrics used in standardize test\n",
        "1. pycocotools (coco RLE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2L4DrqvuRSM"
      },
      "source": [
        "# Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GN5P_NE2whH"
      },
      "source": [
        "# pytorch lib\n",
        "import torch\n",
        "\n",
        "# tensorflow lib\n",
        "import tensorflow as tf\n",
        "\n",
        "# computer vision\n",
        "import cv2\n",
        "\n",
        "# numeric lib\n",
        "import numpy as np\n",
        "\n",
        "# python lib\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-j-4Xqd2N7H"
      },
      "source": [
        "## Intersection over union (IOU)\n",
        "1. For bbox, the intersection\n",
        "    - x1 = max(box1[0], box2[0])\n",
        "    - x2 = min(box1[2], box[2])\n",
        "    - y1 = max(box1[1], box2[1])\n",
        "    - y2 = max(box1[3], box3[3])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-EGIub-499A"
      },
      "source": [
        "def IOU_torch(box_preds, box_labels, format=\"xyxy\"):\n",
        "    '''\n",
        "    Calculates IOU for bboxes\n",
        "    '''\n",
        "    if format == \"xyxy\":\n",
        "        bbox1_x1 = box_preds[..., 0:1] # shape = (n, 1)\n",
        "        bbox1_y1 = box_preds[..., 1:2]\n",
        "        bbox1_x2 = box_preds[..., 2:3]\n",
        "        bbox1_y2 = box_preds[..., 3:4]\n",
        "        bbox2_x1 = box_labels[..., 0:1] \n",
        "        bbox2_y1 = box_labels[..., 1:2]\n",
        "        bbox2_x2 = box_labels[..., 2:3]\n",
        "        bbox2_y2 = box_labels[..., 3:4]\n",
        "\n",
        "    elif format == \"xywh\": #yoloV5 format\n",
        "        bbox1_x1 = box_preds[..., 0:1] - box_preds[..., 2:3] / 2\n",
        "        bbox1_y1 = box_preds[..., 1:2] - box_preds[..., 3:4] / 2\n",
        "        bbox1_x2 = box_preds[..., 0:1] + box_preds[..., 2:3] / 2\n",
        "        bbox1_y2 = box_preds[..., 1:2] + box_preds[..., 3:4] / 2\n",
        "\n",
        "        bbox2_x1 = box_labels[..., 0:1] - box_labels[..., 2:3] / 2\n",
        "        bbox2_y1 = box_labels[..., 1:2] - box_labels[..., 3:4] / 2\n",
        "        bbox2_x2 = box_labels[..., 0:1] + box_labels[..., 2:3] / 2\n",
        "        bbox2_y2 = box_labels[..., 1:2] + box_labels[..., 3:4] / 2\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(\"This bbox format is not supported\")\n",
        "\n",
        "    bbox1_area =  (bbox1_x2-bbox1_x1) * (bbox1_y2-bbox1_y1)\n",
        "    bbox2_area =  (bbox2_x2-bbox2_x1) * (bbox2_y2-bbox2_y1)\n",
        "    \n",
        "    intersection_x1 = torch.max(bbox1_x1,bbox2_x1)\n",
        "    intersection_y1 = torch.max(bbox1_y1,bbox2_y1)\n",
        "    intersection_x2 = torch.min(bbox1_x2,bbox2_x2)\n",
        "    intersection_y2 = torch.min(bbox1_y2,bbox2_y2)\n",
        "\n",
        "    # if the box dont intersect, one or more of the difference will be negative\n",
        "    intersection_area = torch.clamp(intersection_x2-intersection_x1, min=0) * torch.clamp(intersection_y2-intersection_y1, min=0) \n",
        "\n",
        "    return intersection_area / (bbox1_area + bbox2_area- intersection_area + 1e-7) #epilson for stability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_mtmFdv49yU"
      },
      "source": [
        "# test_1 base case xyxy format\n",
        "torch_box_1 = torch.tensor([2,2,6,6])\n",
        "torch_box_2 = torch.tensor([4,4,7,8])\n",
        "assert torch.abs(IOU_torch(torch_box_1,torch_box_2)-torch.tensor([4/24]))< 1e-6, \"Test 1 Wrong!\"\n",
        "\n",
        "# test 2 no intersection xyxy format\n",
        "torch_box_3 = torch.tensor([2,2,4,4])\n",
        "torch_box_4 = torch.tensor([4,4,7,8])\n",
        "assert IOU_torch(torch_box_3,torch_box_4) < torch.tensor([1e-6]), \"Test 2 Wrong!\"\n",
        "\n",
        "# test 3 batch input\n",
        "torch_group_box1 = torch.tensor(\n",
        "        [\n",
        "            [0, 0, 2, 2],\n",
        "            [0, 0, 2, 2],\n",
        "            [0, 0, 2, 2],\n",
        "            [0, 0, 2, 2],\n",
        "            [0, 0, 2, 2],\n",
        "            [0, 0, 3, 2],\n",
        "        ]\n",
        "    )\n",
        "torch_group_box2 = torch.tensor(\n",
        "        [\n",
        "            [3, 0, 5, 2],\n",
        "            [3, 0, 5, 2],\n",
        "            [0, 3, 2, 5],\n",
        "            [2, 0, 5, 2],\n",
        "            [1, 1, 3, 3],\n",
        "            [1, 1, 3, 3],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "assert torch.all(torch.abs(IOU_torch(torch_group_box1,torch_group_box2)-torch.Tensor([0, 0, 0, 0, 1 / 7, 0.25]).reshape(-1,1)) < torch.tensor(([1e-6]*6)).reshape(-1,1)), \"Group test is Wrong!\"\n",
        "\n",
        "# test 4 base case xywh format\n",
        "torch_box_5 = torch.tensor([0.8, 0.1, 0.2, 0.2])\n",
        "torch_box_6 = torch.tensor([0.9, 0.2, 0.2, 0.2])\n",
        "assert torch.abs(IOU_torch(torch_box_5,torch_box_6, format=\"xywh\")-torch.tensor([1/7])) < 1e-6, \"Test 3 Wrong!\"\n",
        "\n",
        "# test 5 no intersection xywh format\n",
        "torch_box_7 = torch.tensor([0.25, 0.15, 0.3, 0.1])\n",
        "torch_box_8 = torch.tensor([0.25, 0.35, 0.3, 0.1])\n",
        "assert IOU_torch(torch_box_7,torch_box_8, format=\"xywh\") < torch.tensor([1e-6]), \"Test 4 Wrong!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTnn0-aGXwz-"
      },
      "source": [
        "## Mean average precision (mAP@ IOU threshold, 0.5,0.55...)\n",
        "\n",
        "1. Get all the bounding box predictions \n",
        "2. Sort by descending confidence score\n",
        "3. calculate precision and recall and plot on curve (PR curve)\n",
        "4. Calculate area under curve\n",
        "5. Repeat for all classes\n",
        "\n",
        "\n",
        "Note:\n",
        "1. precision = TP/All_detection\n",
        "2. recall = TP/All_ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odcgak2949kt"
      },
      "source": [
        "def torch_mean_average_precision(pred_boxes, label_boxes, iou_threshold=0.5, format='xyxy', num_classes=20):\n",
        "    #pred/label boxes [[train_idx, class_pred, prob_score, x1, y1, x2, y2]...]\n",
        "    \n",
        "    average_precisions = []\n",
        "    epsilon = 1e-6\n",
        "\n",
        "    for label_class in range(num_classes):\n",
        "        class_detections = []\n",
        "        class_ground_truths =[]\n",
        "\n",
        "        for pred_box in pred_boxes:\n",
        "            if pred_box[1] == label_class:\n",
        "                class_detections.append(pred_box)\n",
        "\n",
        "        for label_box in label_boxes:\n",
        "            if label_box[1] == label_class:\n",
        "                class_ground_truths.append(label_box)\n",
        "\n",
        "        amount_bboxes = Counter([gt[0] for gt in class_ground_truths]) # {train_idx: n_boxes...}\n",
        "\n",
        "        for key,val in amount_bboxes.items():\n",
        "            amount_bboxes[key] = torch.zeros(val)\n",
        "        # {0: [0,0,0,0]} -> keep track of which grount truth bbox are fulfilled\n",
        "\n",
        "        class_detections.sort(key=lambda x:x[2], reverse=True)\n",
        "        TP = torch.zeros(len(class_detections))\n",
        "        FP = torch.zeros(len(class_detections))\n",
        "\n",
        "        total_true_boxes = len(class_ground_truths)\n",
        "\n",
        "        for detection_idx, detection in enumerate(class_detections):\n",
        "            ground_truth_img = [\n",
        "                                bbox for bbox in class_ground_truths if bbox[0]==detection[0]\n",
        "            ]\n",
        "\n",
        "            num_gts =  len(ground_truth_img)\n",
        "            best_iou = 0\n",
        "\n",
        "            for idx, gt in enumerate(ground_truth_img):\n",
        "                iou = IOU_torch(\n",
        "                    torch.tensor(detection[3:]),\n",
        "                    torch.tensor(gt[3:]),\n",
        "                    format = format\n",
        "                )\n",
        "\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_gt_idx = idx\n",
        "\n",
        "            if best_iou > iou_threshold:\n",
        "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
        "                    TP[detection_idx] = 1\n",
        "                    amount_bboxes[detection[0]][best_gt_idx] =1\n",
        "\n",
        "                else:\n",
        "                    FP[detection_idx] = 1\n",
        "\n",
        "            else:\n",
        "                FP[detection_idx] = 1\n",
        "\n",
        "        TP_cum_sum = torch.cumsum(TP, dim=0)\n",
        "        FP_cum_sum = torch.cumsum(FP, dim=0)\n",
        "        recalls = TP_cum_sum / (total_true_boxes+epsilon)\n",
        "        precisions = torch.divide(TP_cum_sum, (TP_cum_sum+FP_cum_sum+epsilon))\n",
        "        \n",
        "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
        "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
        "        average_precisions.append(torch.trapz(precisions,recalls))\n",
        "    \n",
        "    return sum(average_precisions)/len(average_precisions) #average over all classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN21Ye352NGu"
      },
      "source": [
        "t1_preds = [\n",
        "        [0, 0, 0.9, 0.55, 0.2, 0.3, 0.2],\n",
        "        [0, 0, 0.8, 0.35, 0.6, 0.3, 0.2],\n",
        "        [0, 0, 0.7, 0.8, 0.7, 0.2, 0.2],\n",
        "]\n",
        "t1_targets = [\n",
        "        [0, 0, 0.9, 0.55, 0.2, 0.3, 0.2],\n",
        "        [0, 0, 0.8, 0.35, 0.6, 0.3, 0.2],\n",
        "        [0, 0, 0.7, 0.8, 0.7, 0.2, 0.2],\n",
        "]\n",
        "assert torch.abs(torch_mean_average_precision(t1_preds,t1_targets, format='xywh', num_classes=1) - torch.tensor(1)) < torch.tensor(1e-6), \"test_1 failed\"\n",
        "\n",
        "t3_preds = [\n",
        "        [0, 1, 0.9, 0.55, 0.2, 0.3, 0.2],\n",
        "        [0, 1, 0.8, 0.35, 0.6, 0.3, 0.2],\n",
        "        [0, 1, 0.7, 0.8, 0.7, 0.2, 0.2],\n",
        "]\n",
        "t3_targets = [\n",
        "        [0, 0, 0.9, 0.55, 0.2, 0.3, 0.2],\n",
        "        [0, 0, 0.8, 0.35, 0.6, 0.3, 0.2],\n",
        "        [0, 0, 0.7, 0.8, 0.7, 0.2, 0.2],\n",
        "]\n",
        "assert torch.abs(torch_mean_average_precision(t3_preds,t3_targets, format='xywh', num_classes=1) - torch.tensor(0)) < torch.tensor(1e-6), \"test_2 failed\"\n",
        "\n",
        "t4_preds = [\n",
        "            [0, 0, 0.9, 0.15, 0.25, 0.1, 0.1],\n",
        "            [0, 0, 0.8, 0.35, 0.6, 0.3, 0.2],\n",
        "            [0, 0, 0.7, 0.8, 0.7, 0.2, 0.2],\n",
        "        ]\n",
        "\n",
        "t4_targets = [\n",
        "            [0, 0, 0.9, 0.55, 0.2, 0.3, 0.2],\n",
        "            [0, 0, 0.8, 0.35, 0.6, 0.3, 0.2],\n",
        "            [0, 0, 0.7, 0.8, 0.7, 0.2, 0.2],\n",
        "        ]\n",
        "\n",
        "assert torch.abs(torch_mean_average_precision(t4_preds,t4_targets, format='xywh', num_classes=1) - torch.tensor(5 / 18)) < torch.tensor(1e-6), \"test_3 failed\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y2woDtloYVf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gotu_w3v1oAt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE3G2S1g4vxs"
      },
      "source": [
        "## Resources\n",
        "\n",
        "1. IOU pytorch implementation\n",
        "    - https://www.youtube.com/watch?v=XXYG5ZWtjj0\n",
        "2. IOU segmantic segmentation\n",
        "    - https://www.youtube.com/watch?v=0FmNxqLFeYo&t=1s\n",
        "3. Mean Average Precision pytorch implementation\n",
        "    - https://www.youtube.com/watch?v=FppOzcDvaDI\n",
        "    - https://www.youtube.com/watch?v=c45jSJ3WGds\n",
        "\n",
        "4. Non maximum supression\n",
        "    - https://towardsdatascience.com/implementation-of-mean-average-precision-map-with-non-maximum-suppression-f9311eb92522\n",
        "    - https://www.youtube.com/watch?v=YDkjWEN8jNA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRRM-NQvfOYk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}